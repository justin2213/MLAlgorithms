{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fbdc778-79a2-479f-8ec3-ccd06c530bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import svm, metrics, datasets\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeedb57b-dd6d-45dd-9e20-8c2f0c1731ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_image_files(container_path, dimension=(64, 64), max_images_per_class=1000):\n",
    "    \"\"\"\n",
    "    Load a limited number of image files with categories as subfolder names \n",
    "    which performs like scikit-learn sample dataset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    container_path : string or unicode\n",
    "        Path to the main folder holding one subfolder per category\n",
    "    dimension : tuple\n",
    "        size to which images are adjusted to\n",
    "    max_images_per_class : int\n",
    "        Maximum number of images to load per class\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Bunch\n",
    "    \"\"\"\n",
    "    image_dir = Path(container_path)\n",
    "    folders = [directory for directory in image_dir.iterdir() if directory.is_dir()]\n",
    "    categories = [folder.name for folder in folders]\n",
    "\n",
    "    descr = \"A image classification dataset\"\n",
    "    images = []\n",
    "    flat_data = []\n",
    "    target = []\n",
    "    \n",
    "    for i, direc in enumerate(folders):\n",
    "        count = 0  # Counter to limit number of images per class\n",
    "        for file in direc.iterdir():\n",
    "            if count >= max_images_per_class:\n",
    "                break  # Stop if we've reached the limit for this class\n",
    "            img = imread(file)\n",
    "            img_resized = resize(img, dimension, anti_aliasing=True, mode='reflect')\n",
    "            flat_data.append(img_resized.flatten()) \n",
    "            images.append(img_resized)\n",
    "            target.append(i)\n",
    "            count += 1  # Increment the counter\n",
    "            print(count, i)\n",
    "        \n",
    "    flat_data = np.array(flat_data)\n",
    "    target = np.array(target)\n",
    "    images = np.array(images)\n",
    "\n",
    "    return Bunch(data=flat_data,\n",
    "                 target=target,\n",
    "                 target_names=categories,\n",
    "                 images=images,\n",
    "                 DESCR=descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1697d453-0462-4c7a-bf88-dd105e2b0566",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/path/to/dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m param_grids \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1000\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m]},\n\u001b[1;32m      3\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1000\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;241m0.0001\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m]},\n\u001b[1;32m      4\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1000\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;241m0.0001\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoef0\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m      5\u001b[0m ]\n\u001b[0;32m----> 6\u001b[0m image_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_image_files\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/path/to/dataset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m      8\u001b[0m     image_dataset\u001b[38;5;241m.\u001b[39mdata, image_dataset\u001b[38;5;241m.\u001b[39mtarget, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m109\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m grid \u001b[38;5;129;01min\u001b[39;00m param_grids:\n",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m, in \u001b[0;36mload_image_files\u001b[0;34m(container_path, dimension, max_images_per_class)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mLoad a limited number of image files with categories as subfolder names \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mwhich performs like scikit-learn sample dataset\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mBunch\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m image_dir \u001b[38;5;241m=\u001b[39m Path(container_path)\n\u001b[0;32m---> 20\u001b[0m folders \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage_dir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     21\u001b[0m categories \u001b[38;5;241m=\u001b[39m [folder\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m folder \u001b[38;5;129;01min\u001b[39;00m folders]\n\u001b[1;32m     23\u001b[0m descr \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA image classification dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/pathlib.py:1056\u001b[0m, in \u001b[0;36mPath.iterdir\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miterdir\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Yield path objects of the directory contents.\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m \n\u001b[1;32m   1053\u001b[0m \u001b[38;5;124;03m    The children are yielded in arbitrary order, and the\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;124;03m    special entries '.' and '..' are not included.\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1057\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_child_relpath(name)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/path/to/dataset'"
     ]
    }
   ],
   "source": [
    "param_grids = [\n",
    "    {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "    {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "    {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'coef0': [0, 1, 10], 'kernel': ['sigmoid']}\n",
    "]\n",
    "image_dataset = load_image_files('/path/to/dataset')\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    image_dataset.data, image_dataset.target, test_size=0.3, random_state=109)\n",
    "\n",
    "for grid in param_grids:\n",
    "    svc = svm.SVC(random_state=42)\n",
    "    \n",
    "    # Perform GridSearchCV with the kernel\n",
    "    clf = GridSearchCV(svc, grid, cv=5)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the labels for the test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Display confusion matrix with correct labels\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        clf, X_test, y_test,\n",
    "        display_labels=image_dataset.target_names,\n",
    "        values_format='d'\n",
    "    )\n",
    "    \n",
    "    # Rotate the x-axis labels\n",
    "    plt.xticks(rotation=90, ha='right')\n",
    "    \n",
    "    # Show the confusion matrix\n",
    "    plt.show()\n",
    "    \n",
    "    # Print the classification report\n",
    "    print(\"Classification report for - \\n{}:\\n{}\\n\".format(\n",
    "        clf, metrics.classification_report(y_test, y_pred)\n",
    "    ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e55b552-983d-4ecb-a768-e6f54c307286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
